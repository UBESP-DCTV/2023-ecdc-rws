---
title: '[Day Three]{style="color:darkblue"}:<br>[Import]{style="color:darkorange;"}'
subtitle: "50 min approx"
format:
  revealjs:
    width:  1648 #(3/2)
    height: 1080
    logo: img/UBEP.png
    footer: "UBEP's R training for supervisors"
    slide-number: true
    history: false
    preview-links: auto
    code-link: true
    multiplex: true
    df-print: paged
    chalkboard: 
      src: src/chalkboard-pipes-and-visualization.json
output-location: column
bibliography: references.bib
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set( 
  echo = TRUE,
  results = "hold"
)
options(width = 65)
library(countdown)
```

# Overview {style="color:darkblue;"}

## 

::: columns
::: {.column width="50%"}
### Questions

-   How data can be imported end exported from/to files on disk?
-   How basic data import issues can be assessed?
:::

::: {.column width="50%"}
### Lesson Objectives

#### To be able to

-   Read/write tabular data from a file into R.
-   Know basics of base R `?read.csv`, and `?write.csv`.
-   Know basics of `?readr::read_csv`, and `?readr::write_csv`.
-   Know basics of `{heaven}` package.
-   Working with `?rio::import`, and `?rio::export`.
-   Mange presence/absence/multiple-empty header lines in source data.
-   Select best data variable/column names for working with code
-   Handle missing data (including empty rows and columns).
:::
:::

# Part I: R Import/Export

## Data file

For doing real data analyses, we need to interact with the *external* world with data. Reading and writing them.

Mainly, we will work with the so-called rectangular data. I.e., information that can be organized in a tables:

-   all columns (AKA variables) have the same number of rows.
-   all rows (AKA observations) have the same number of columns
-   each data value correspond to a single row-column pair within the table.

![](img/tidy-data-R4DS.png)

## Reminder on data frames

R tabular data structure is the `data.frame`

::: columns
::: {.column width="50%"}
```{r}
#| eval: FALSE
#| paged.print: FALSE
mtcars
```

```{r}
#| output-location: default
class(mtcars)
```

::: callout-warning
Row names are not data, but an attribute of the data frame, so `as_tibble` will remove them.
:::
:::

::: {.column width="50%"}
```{r}
#| paged.print: FALSE
#| echo: FALSE
mtcars
```
:::
:::

In the tidyverse, we will use a modern version of the data frame called *tibble* (class: `tbl_df`)

::: columns
::: {.column width="50%"}
```{r}
#| output: false
library(tidyverse)

mtcars_tbl <- as_tibble(mtcars)
mtcars_tbl
```

```{r}
#| output-location: default
# `tibble`s are `data.frame`s!
class(mtcars_tbl) 
```
:::

::: {.column width="50%"}
```{r}
#| paged.print: FALSE
#| echo: FALSE
library(tidyverse)

mtcars_tbl <- as_tibble(mtcars)
mtcars_tbl
```
:::
:::

## Reminder on data frames

R tabular data structure is the `data.frame`

::: columns
::: {.column width="50%"}
```{r}
#| eval: FALSE
#| paged.print: FALSE
mtcars
```

```{r}
#| output-location: default
class(mtcars)
```

::: callout-warning
Row names are not data, but an attribute of the data frame, so `as_tibble` will remove them.

To keep row names, use `rownames = "<name>"`.
:::
:::

::: {.column width="50%"}
```{r}
#| paged.print: FALSE
#| echo: FALSE
mtcars
```
:::
:::

In the tidyverse, we will use a modern version of the data frame called *tibble* (class: `tbl_df`)

::: columns
::: {.column width="50%"}
```{r}
#| paged.print: FALSE
#| output: false
library(tidyverse)

mtcars_tbl <- as_tibble(
  mtcars,
  rownames = "model"
)
mtcars_tbl
```

```{r}
#| output-location: default
# `tibble`s are `data.frame`s!
class(mtcars_tbl) 
```
:::

::: {.column width="50%"}
```{r}
#| paged.print: FALSE
#| echo: FALSE
library(tidyverse)

mtcars_tbl <- as_tibble(
  mtcars,
  rownames = "model"
)
mtcars_tbl
```
:::
:::

## Plain Vs. non-plain text data

Tabular data can be (quite always) saved as a plain text, readable by anyone, on every computer.

::: columns
::: {.column width="50%"}
Most common plain-text tabular data file format is "CSV", i.e., Comma-Separated Value.

``` csv
id,age,weigth
1,47,80
2,51,76
3,27,92
```

Extension for those files is `.csv` (e.g., `data.csv`)

::: {.fragment .fade-in}
::: callout-warning
In EU, we use a comma to separate decimal digits instead of a dot. For this reason, it would be ambiguous to use comma to separate field in CSV, which must use quotes in those cases. For this reason, there is an alternative version of CSV, called CSV2 (using the same file extension `.csv`!!) which uses a semicolon to separate fields and can use comma for numbers.

::: columns
::: {.column widht="50%"}
CSV

``` csv
id,age,weigth
1,47,"80,4"
2,51,"76,3"
3,27,"92"
```
:::

::: {.column widht="50%"}
CSV2

``` csv
id;age;weigth
1;47;80,4
2;51;76,3
3;27;92
```
:::
:::
:::
:::
:::

::: {.column width="50%"}
On the other hand, it could be difficult to collect data in plain text, and often they are collected by other software, e.g., Excel, in non-plain text format.

![](img/excel-data.png)

Extension for those files is `.xlsx` (e.g., `data.xlsx`)
:::
:::

## Base R

-   read CSV with `?read.csv`

::: panel-tabset
## From disk

```{r}
#| paged.print: FALSE
library(here)

data_path <- here("data-raw", "Copenhagen_clean.csv")
read.csv(data_path) |> 
  head()
```

## From web

```{r}
#| paged.print: FALSE
read.csv("https://pos.it/r4ds-students-csv") |> 
  head()
```

## From text

> You must use `text` argument to read from literal text

```{r}
#| paged.print: FALSE
read.csv(
  text =
'id,age,weigth
1,47,80.4
2,51,76.3
3,27,92'
) |> 
  head()
```
:::

## Tidyverse

-   read CSV with `?read_csv`

::: panel-tabset
## From disk

```{r}
#| paged.print: FALSE
library(here)
library(tidyverse)

data_path <- here("data-raw", "Copenhagen_clean.csv")
read_csv(data_path)
```

## From web

```{r}
#| paged.print: FALSE
read_csv("https://pos.it/r4ds-students-csv")
```

## From text

```{r}
#| paged.print: FALSE
read_csv(
'id,age,weigth
1,47,80.4
2,51,76.3
3,27,92'
)
```
:::

## Non plain-text data

::: panel-tabset
## Excel

```{r}
#| paged.print: FALSE
library(readxl)
here("data-raw", "Copenhagen_clean.xlsx") |> 
  read_excel()
```

## SAS

```{r}
#| paged.print: FALSE
library(haven)

read_sas(
  "http://www.principlesofeconometrics.com/sas/airline.sas7bdat"
)
```

## STATA

```{r}
#| paged.print: FALSE
library(haven)
# read_stata()

```

## SPSS

```{r}
#| paged.print: FALSE
library(haven)
# read_spss()
```
:::

## `{rio}`

From one side, it could be better to use `{tidyverse}` functions (i.e., `{readr}` ones, which is part of the Tidyverse) to read tabular data into R because of a more consistent naming and arguments.

But, we still need `{haven}` to read SAS, SPSS, STATA, and other types of data, and we need `{readxl}` to read Excel files. Moreover, we still need to recognize and link the file type with the function used to read it.

::: callout-tip
We can use the `{rio}` package to read them all!

-   `?rio::import` provides a painless data import experience by automatically choosing the appropriate import/read function based on file extension (or a specified format argument)

-   `?rio::export` provides the same painless file recognition for data export/write functionality
:::

## `{rio}` - read

::: panel-tabset
## CSV

```{r}
#| paged.print: FALSE
library(here)
library(rio)

# {rio} default import is a simple data.frame
here("data-raw", "Copenhagen_clean.csv") |> 
  import() |> 
  head()
```

## Excel

```{r}
#| paged.print: FALSE
library(here)
library(rio)

# {rio} default import is a simple data.frame.
# But, class of imported object can be asked
# to be a tibble!
here("data-raw", "Copenhagen_clean.xlsx") |> 
  import(setclass = "tibble")
```

## SAS

```{r}
#| paged.print: FALSE
library(here)
library(rio)

# {rio} default import is a simple data.frame
# You can also set the {rio} import class globally
options(rio.import.class = "tibble")

import(
  "http://www.principlesofeconometrics.com/sas/airline.sas7bdat"
)
```

## STATA

## SPSS
:::

... and [many other](https://gesistsa.github.io/rio/#supported-file-formats)

## `{rio}` - write

::: panel-tabset
## CSV

```{r}
#| paged.print: FALSE
Copenhagen_clean <- here("data-raw", "Copenhagen_clean.csv") |> 
  import()

Copenhagen_clean |> 
  # export() returns the output path
  # so, we can pipe it back to import
  export(here("output", "Copenhagen_clean.csv")) |> 
  import()
```

## Excel

```{r}
#| paged.print: FALSE
Copenhagen_clean |> 
  export(here("output", "Copenhagen_clean.xlsx")) |> 
  import()
```

## SAS

```{r}
#| paged.print: FALSE
Copenhagen_clean |> 
  export(here("output", "Copenhagen_clean.sas7bdat")) |> 
  import()
```

## STATA

```{r}
#| paged.print: FALSE
Copenhagen_clean |> 
  export(here("output", "Copenhagen_clean.dta")) |> 
  import()
```

## SPSS

```{r}
#| paged.print: FALSE
Copenhagen_clean |> 
  export(here("output", "Copenhagen_clean.sav")) |> 
  import()
```
:::

## `{rio}` - multiple-sheets Excel

You can directly save a multi-sheet Excel file writing a list of data frames...

::: columns
::: {.column width="50%"}
### single file, multi-sheets

```{r}
#| output-location: default
list(mtcars = mtcars, iris = iris) |> 
  export(here("output", "r-data.xlsx"))
```

### multiple files, single-sheet

```{r}
#| output-location: default
list(mtcars = mtcars, iris = iris) |> 
  # "\%s" is the name placeholder from list names
  export_list(here("output", "%s.xlsx"))
```
:::

::: {.column width="50%"}
![](img/mtcars-iris-excel.png)
:::
:::

## `{rio}` - multiple-sheets Excel

... and import multiple sheet data in a (list of) data frame(s)

### list of dataframes, from single multi-sheets file

```{r}
import_list(here("output", "r-data.xlsx")) |> 
  str(1) # structure up to first nested level
```

### single dataframe, from multiple ones binded by rows

(from multiple files w/ same colnames)

```{r}
c(
  here("output", "mtcars.xlsx"),
  here("output", "mtcars.xlsx")
) |>
  import_list(rbind = TRUE) |> 
  str(0) # structure for the top level only
```

## My turn

YOU: Connect to our [pad](https://bit.ly/ubep-rws-pad) (<https://bit.ly/ubep-rws-pad>) and write there questions & doubts (and if I am too slow or too fast)

ME: Connect to the Day-3 project in RStudio cloud (<https://bit.ly/ubep-rws-rstudio>): script `09-import.R`

## Your turn

::: callout-caution
## Your turn

-   Connect to our [pad](https://bit.ly/ubep-rws-pad)(<https://bit.ly/ubep-rws-pad>)

-   Connect to the Day-2 project in RStudio cloud (<https://bit.ly/ubep-rws-rstudio>)

...and:
:::

1.  Which function(s) can you use to read excel data from disk?

    -   `import_excel`
    -   `read`
    -   `import`

2.  Then, open the script `08-rio.R` and follow the instruction step by step.

::: {.fragment .fade-out fragment-index="1"}
```{r}
#| echo: false
countdown(
  minutes = 5,
  left = "25%",
  right = "25%",
  top = "70%",
  bottom = 0,
  blink_colon = TRUE,
  play_sound = TRUE,
  margin = "5%",
  font_size = "4em"
)
```
:::

::: {.fragment .fade-in fragment-index="1"}
::: callout-important
-   you can use `rio::import` to read tabular data, it will process the file properly based on its extension and content.
-   you can use `rio::export` to write tabular data (most of format), simply providing the correct extension.
:::
:::

# Part II: Cleaning imported data

## Standard data issues

Often, when data where collected in real life in Excel, they do not have an optimal shape for importing them into programs.

::: columns
::: {.column width="50%"}
You can have:

-   leading header's groups
-   empty columns and rows
-   multi-line headers
-   space and special characters in names
-   missing information
-   repeated-data reported at first occurrence only
:::

::: {.column width="50%"}
![](img/cop-headers.png){.absolute top="15%" right="10%"}

![](img/cop-first-only.png){.absolute top="20%" right="15%"}

![](img/cop-multiline.png){.absolute top="40%" right="10%"}
:::
:::

. . .

::: columns
::: {.column width="50%"}
::: callout-caution
## Your turn

-   Connect to our [pad](https://bit.ly/ubep-rws-pad)(<https://bit.ly/ubep-rws-pad>)

1.  List all other issue you have ever encounter in importing/cleaning data (or you can imagine could happen, if this is the first time you import data on software for data analyses)
:::
:::
:::

```{r}
#| echo: false
countdown(
  minutes = 1,
  left = "45%",
  right = "5%",
  top = "70%",
  bottom = 0,
  blink_colon = TRUE,
  play_sound = TRUE,
  margin = "5%",
  font_size = "4em"
)
```

## Headers - skip-them-all {auto-animate="true"}

We can completely skip the headers, and manually assign col names

::: callout-tip
`rio::import` useful options:

-   `skip = n`: ignore first n lines
-   `header = FALSE` = doesn't use (first-line-after-skipped) data to create headers.
:::

```{r}
db_raw <- here("data-raw", "Copenhagen_raw.xlsx") |> 
  # ignore first 4 lines
  # do not any header in import
  import(skip = 4, header = FALSE)
db_raw
```

## Headers - manual defined headers {auto-animate="true"}

We can completely skip the headers, and manually assign col names

::: callout-tip
`rio::import` useful options:

-   `skip = n`: ignore first n lines
-   `header = FALSE` = doesn't use (first-line-after-skipped) data to create headers.
:::

```{r}
#| code-line-numbers: "6-12"
db_raw <- here("data-raw", "Copenhagen_raw.xlsx") |> 
  # ignore first 4 lines
  # do not any header in import
  import(skip = 4, header = FALSE)

# so we can define proper name manually...
col_names <- paste(
  sample(letters, 43, replace = TRUE),
  1:43,
  sep = "_"
)
col_names
```

## Headers - set manual headers {auto-animate="true"}

We can completely skip the headers, and manually assign col names

::: callout-tip
`rio::import` useful options:

-   `skip = n`: ignore first n lines
-   `header = FALSE` = doesn't use (first-line-after-skipped) data to create headers.
:::

```{r}
#| code-line-numbers: "13-14"
db_raw <- here("data-raw", "Copenhagen_raw.xlsx") |> 
  # ignore first 4 lines
  # do not any header in import
  import(skip = 4, header = FALSE)

# so we can define proper name manually...
col_names <- paste(
  sample(letters, 43, replace = TRUE),
  1:43,
  sep = "_"
)

names(db_raw) <- col_names
db_raw
```

## Headers - `{unheadr}` {auto-animate="true"}

The `{unheadr}` package purpose is exactly: "...functions to work with messy data, often derived from spreadsheets...", in particular, its `?unheadr::mash_colnames` makes many header rows into column names.

::: columns
::: {.column width="30%"}
::: callout-important
For `{unheadr}` to work, the best option is to `rio::import` all the data **without considering any structure**, so that with `header = FALSE` activated. If so, we can keep `n_name_rows = n` with `n` exactly equal to the number of rows that compose the header.
:::

::: callout-tip
## Note

-   All the spreadsheet content is imported as data, and all columns are parsed as `character`s.
-   Actual column names are meaningless now, so we will set `keep_names = FALSE`.
:::
:::

::: {.column width="70%"}
```{r}
#| code-line-numbers: "10"
library(rio)
library(here)
library(unheadr)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE)
```

::: callout-caution
## What's next

First topmost header row is a grouping name for columns. In Excel, reported in the first column of each group (even if cells are merged).
:::
:::
:::

## Headers - `{unheadr}` {auto-animate="true"}

The `{unheadr}` package purpose is exactly: "...functions to work with messy data, often derived from spreadsheets...", in particular, its `?unheadr::mash_colnames` makes many header rows into column names.

::: columns
::: {.column width="30%"}
::: callout-important
If we have a (single!) topmost leading rows of grouping column names, and we like to maintain them (otherwise `skip = 1`), we will activate the option `sliding_headers = TRUE`. Setting the `n_name_rows = n` accordingly.
:::

::: callout-tip
## Note

-   The group column names are repeated forward to all the empty columns up to the next non empty one.
:::
:::

::: {.column width="70%"}
```{r}
#| code-line-numbers: "11-15"
library(rio)
library(here)
library(unheadr)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 1,
    sliding_headers = TRUE
  )
```

::: callout-caution
## What's next

We need to include all the other three header rows in the colnames, merging them with the corresponding group name.
:::
:::
:::

## Headers - `{unheadr}` {auto-animate="true"}

The `{unheadr}` package purpose is exactly: "...functions to work with messy data, often derived from spreadsheets...", in particular, its `?unheadr::mash_colnames` makes many header rows into column names.

::: columns
::: {.column width="30%"}
::: callout-important
Including in `n_name_rows = n` all the rows composing the header(s) (topmost grouping one eventually included!), `{unheadr}` will merge them all using underscores (i.e., `_`) to separate words.
:::

::: callout-tip
## Note

-   Considering all the rows composing the header is enough to complete the import.

This way, even if multiple column have the same name on distinct groups, we keep distinct column names in our imported dataset!
:::
:::

::: {.column width="70%"}
```{r}
#| code-line-numbers: "13"
library(rio)
library(here)
library(unheadr)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 4,
    sliding_headers = TRUE
  )
```

::: callout-caution
## What's next

Now that we have merged all the rows reporting column names components, it is extremely useful to guarantee that naming are syntactically correct and with a consistent convention across the dataset.
:::
:::
:::

## Variable names {auto-animate="true"}

`{janitor}` can also convert colnames consistently in a specific convention.[^1]

[^1]: *snake_case* by default. See the [Artwork](img/cases.jpeg) by [Allison Horst](https://allisonhorst.com/).

```{r}
#| code-line-numbers: "4,17"
library(rio)
library(here)
library(unheadr)
library(janitor)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 4,
    sliding_headers = TRUE
  ) |> 
  clean_names()
```

::: callout-caution
## What's next

Now colnames are fine, but still some empty column and rows in the dataset, we would like to remove to have a clean structure.
:::

## Empty rows and columns {auto-animate="true"}

We can use `{janitor}` package to remove empty columns and rows.

```{r}
#| code-line-numbers: "18"
library(rio)
library(here)
library(unheadr)
library(janitor)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 4,
    sliding_headers = TRUE
  ) |> 
  clean_names() |> 
  remove_empty(c("rows", "cols"))
```

::: callout-caution
## What's next

We have finished working on meta-data now. We can start to look at the data them self. First, `demo_sex` column as implicit repeated values we would like to make explicit.
:::

## Fill default content {auto-animate="true"}

```{r}
#| code-line-numbers: "5,20"
library(rio)
library(here)
library(unheadr)
library(janitor)
library(tidyverse)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(header = FALSE) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 4,
    sliding_headers = TRUE
  ) |> 
  clean_names() |> 
  remove_empty(c("rows", "cols")) |> 
  fill(demo_sex)
```

::: callout-important
To fill the implicit content within the data, we can use the `{tidyr}` package, which is part of the `{tidyverse}`, and automatically attached by it.
:::

::: callout-caution
## What's next

We are quite to the end, we only need to make consistent convention for missing information. They are both reported as empty (already parsed as `NA`, correctly) and with `??`. We need to tell `rio::import` that also them are missing information
:::

## Missing data {auto-animate="true"}

```{r}
#| code-line-numbers: "14"
library(rio)
library(here)
library(unheadr)
library(janitor)
library(tidyverse)
options(rio.import.class = "tibble")

here(
  "data-raw",
  "Copenhagen_raw.xlsx"
) |> 
  import(
    header = FALSE,
    na = c("", "??")
  ) |> 
  mash_colnames(
    keep_names = FALSE,
    n_name_rows = 4,
    sliding_headers = TRUE
  ) |> 
  clean_names() |> 
  remove_empty(c("rows", "cols")) |> 
  fill(demo_sex)
```

## My turn

YOU: Connect to our [pad](https://bit.ly/ubep-rws-pad) (<https://bit.ly/ubep-rws-pad>) and write there questions & doubts (and if I am too slow or too fast)

ME: Connect to the Day-3 project in RStudio cloud (<https://bit.ly/ubep-rws-rstudio>): script `10-cleaning.R`

## Your turn (Break included)

::: callout-caution
## Your turn

-   Connect to our [pad](https://bit.ly/ubep-rws-pad)(<https://bit.ly/ubep-rws-pad>)

-   Connect to the Day-2 project in RStudio cloud (<https://bit.ly/ubep-rws-rstudio>)

...and:
:::

1.  Before to evaluate it, in the pad, under the section `2.2. Ex17`, write (in a new line) which code will you use to perform the import as required there.

2.  Then, open the script `09-clean.R` and follow the instruction step by step.

::: {.fragment .fade-out fragment-index="1"}

```{r}
#| echo: false
countdown(
  minutes = 15,
  left = "25%",
  right = "25%",
  top = "70%",
  bottom = 0,
  blink_colon = TRUE,
  play_sound = TRUE,
  margin = "5%",
  font_size = "4em"
)
```
:::

::: {.fragment .fade-in fragment-index="1"}
::: callout-important
Most often you will not have to manage multi-row header nor implicit information. Depending on your data, missing information can be coded not with simple empty cells, so that you would need to set `na = c()` explicitly. On the other hand, the pattern

``` r
library(rio)
library(here)
library(janitor)

db <- here(<path>) |> 
  import() |> 
  clean_names() |> 
  remove_empty(c("rows", "cols"))
```

will be quite standard anytime!
:::
:::


## Acknowledgment {.smaller}

To create the current lesson, we explored, used, and adapted content from the following resources:

-   [Hadley Wickham](https://hadley.nz/)'s [R for Data Science (2e)](https://r4ds.hadley.nz/)

-   [rio](https://gesistsa.github.io/rio/) package.

-   [unheadr](https://unheadr.liomys.mx/) package.

-   [janitor](https://sfirke.github.io/janitor/) package.

-   [janitor](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html) showcase

The slides are made using [Posit](https://posit.co/)'s [Quarto](https://quarto.org/) open-source scientific and technical publishing system powered in R by [Yihui Xie](https://yihui.org/)'s [Kintr](https://yihui.org/knitr/).

### Additional resources

-   [Luis D. Verde Arregoitia](https://luisdva.github.io/) [Data Cleaning with R](https://rfortherestofus.com/courses/data-cleaning/)

### License

```{=html}
 <p xmlns:cc="http://creativecommons.org/ns#" ><a rel="cc:attributionURL" href="https://github.com/UBESP-DCTV/2023-ecdc-rws">This work</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://github.com/CorradoLanera">Corrado Lanera, Ileana Baldi, and Dario Gregori</a> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p> 
```
### References
